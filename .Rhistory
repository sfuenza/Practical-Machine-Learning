names(data[1])
names(data[1:8])
names(data[1:7])
names(data[,1:7])
nsv<-nearZeroVar(data,saveMetrics=TRUE)
nsv
data<-data[,8:length(data)]
names(data[1])
nsv<-nearZeroVar(data,saveMetrics=TRUE)
rownames(nsv[nzv==TRUE])
rownames(nsv[nzv==TRUE,])
rownames(nsv[nsv$nzv==TRUE,])
data1<-data[,-which(names(data) %in% rownames(nsv[nsv%nzv==TRUE,]))]
which(names(data) %in% rownames(nsv[nsv%nzv==TRUE,]))
names(datya)
names(data)
rownames(nsv[nsv%nzv==TRUE,])
data1<-data[,-which(names(data) %in% rownames(nsv[nsv$nzv==TRUE,]))]
summary(data1)
nonNAs <- function(x) {
as.vector(apply(x, 2, function(x) length(which(!is.na(x)))))
}
colcnts <- nonNAs(data1)
colnames<-names(data1)
drops <- c()
for (cnt in 1:length(colcnts)) {
if (colcnts[cnt] < nrow(data1)) {
drops <- c(drops, colnames[cnt])
}
}
data1$kurtosis_roll_belt
summary(data1$kurtosis_roll_belt)
length(which(!is.na(data1$kurtosis_roll_belt)))
colcnts<19622*0.8
sum(colcnts<19622*0.8)
sum(colcnts<19622*0.7)
sum(colcnts<19622*0.6)
sum(colcnts<19622*0.5)
sum(colcnts<19622*0.4)
sum(colcnts<19622*0.3)
sum(colcnts<19622*0.2)
sum(colcnts<19622*0.1)
sum(colcnts<19622*0.05)
sum(colcnts<19622*0.04)
sum(colcnts<19622*0.03)
sum(colcnts<19622*0.01)
sum(colcnts<19622*0.02)
sum(colcnts<19622*0.03)
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
test_data<-read.csv("pml-testing.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
train_data1<-train_data[,8:length(train_data)]
test_data1<-test_data[,8:length(test_data)]
sum(!is.na(train_data1[,1]))
sum(!is.na(train_data1[,2]))
sum(!is.na(train_data1[,3]))
sum(!is.na(train_data1[,4]))
sum(!is.na(train_data1[,5]))
names(train_data1[,5])
names(train_data1[5])
for(i in 1:length(train_data))
{
drop_col<-c()
total_no_NA<-sum(!is.na(train_data1[,i]))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<length(train_data)*0.3)
{
drop_col<-c(drop_col,names(train_data1[i]))
}
}
for(i in 1:length(train_data1))
{
drop_col<-c()
total_no_NA<-sum(!is.na(train_data1[,i]))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<length(train_data)*0.3)
{
drop_col<-c(drop_col,names(train_data1[i]))
}
}
for(i in 1:length(train_data1))
{
drop_col<-c()
total_no_NA<-sum(!is.na(train_data1[,i]))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<length(train_data1)*0.3)
{
drop_col<-c(drop_col,names(train_data1[i]))
}
}
drop_col<-c()
for(i in 1:length(train_data1))
{
total_no_NA<-sum(!is.na(train_data1[,i]))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<length(train_data1)*0.3)
{
drop_col<-c(drop_col,names(train_data1[i]))
}
}
nsv<-nearZeroVar(train_data1,saveMetrics=TRUE)
train_data2<-train_data1[,-which(names(train_data1) %in% nsv[nsv$nzv==TRUE,])]
nsv[nsv$nzv==TRUE,]
train_data2<-train_data1[,-which(names(train_data1) %in% row.names(nsv[nsv$nzv==TRUE,]))]
test_data2<-test_data1[,-which(names(test_data1) %in% row.names(nsv[nsv$nzv==TRUE,]))]
drop_col<-c()
for(i in 1:length(train_data2))
{
total_no_NA<-sum(!is.na(train_data2[,i]))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<length(train_data2)*0.3)
{
drop_col<-c(drop_col,names(train_data2[i]))
}
}
drop_col<-c()
total_no_NA<-c()
for(i in 1:length(train_data2))
{
total_no_NA<-c(total_no_NA,sum(!is.na(train_data2[,i])))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<length(train_data2)*0.3)
{
drop_col<-c(drop_col,names(train_data2[i]))
}
}
length(train_data2)
drop_col<-c()
total_no_NA<-c()
for(i in 1:length(train_data2))
{
total_no_NA<-c(total_no_NA,sum(!is.na(train_data2[,i])))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<length(train_data2[,i])*0.3)
{
drop_col<-c(drop_col,names(train_data2[i]))
}
}
total_no_NA<length(train_data2[,1])*0.3
total_no_NA<length(train_data2[1,])*0.3
total_no_NA<length(train_data2[,1])*0.3
total_no_NA<nrow(train_data2[,i])*0.3
total_no_NA<nrow(train_data2[,1])*0.3
total_no_NA<nrow(train_data2[,2])*0.3
total_no_NA<nrow(train_data2[,3])*0.3
total_no_NA<nrow(train_data2[])*0.3
total_no_NA<nrow(train_data2[1,])*0.3
total_no_NA<nrow(train_data2[,1])*0.3
drop_col<-c()
for(i in 1:length(train_data2))
{
total_no_NA<sum(!is.na(train_data2[,i]))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<nrow(train_data2[,i])*0.3)
{
drop_col<-c(drop_col,names(train_data2[i]))
}
}
nrow(train_data2[,1])
nrow(train_data2[,2])
nrow(train_data2[1,])
nrow(train_data2[2,])
nrow(train_data2[])
nrow(train_data2[,1])
nrow(train_data2[,])
nrow(train_data2[,3])
nrow(train_data2[,4])
drop_col<-c()
for(i in 1:length(train_data2))
{
total_no_NA<sum(!is.na(train_data2[,i]))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<nrow(train_data2)*0.3)
{
drop_col<-c(drop_col,names(train_data2[i]))
}
}
total_no_NA<nrow(train_data2)*0.3
drop_col<-c()
for(i in 1:length(train_data2))
{
total_no_NA<-sum(!is.na(train_data2[,i]))
##We look for columns that have more than 30% of the rows with data
if(total_no_NA<nrow(train_data2)*0.3)
{
drop_col<-c(drop_col,names(train_data2[i]))
}
}
nsv
?nearZeroVar
nsv[nsv$freqRatio>10,]
sum(nsv[nsv$freqRatio>10,]$nzv)
sum(nsv[nsv$freqRatio>5,]$nzv)
sum(nsv[nsv$freqRatio>4,]$nzv)
sum(nsv[nsv$freqRatio>3,]$nzv)
sum(nsv$nzv)
length(nsv[nsv$freqRatio>10,]$nzv)
length(nsv[nsv$freqRatio>5,]$nzv)
length(nsv[nsv$freqRatio>4,]$nzv)
length(nsv[nsv$freqRatio>3,]$nzv)
length(nsv[nsv$freqRatio>2,]$nzv)
length(nsv[nsv$freqRatio>1,]$nzv)
length(nsv[nsv$freqRatio>1.5,]$nzv)
length(nsv[nsv$freqRatio>1.4,]$nzv)
length(nsv[nsv$percentUnique>1,]$nzv)
length(nsv[nsv$percentUnique>1.2,]$nzv)
length(nsv[nsv$percentUnique>1.5,]$nzv)
length(nsv[nsv$percentUnique>2,]$nzv)
length(nsv[nsv$percentUnique>1.8,]$nzv)
length(nsv[nsv$percentUnique>1.8 & nsv$nzv==FALSE,]$nzv)
length(nsv[nsv$percentUnique>1.7 & nsv$nzv==FALSE,]$nzv)
length(nsv[nsv$percentUnique>1.9 & nsv$nzv==FALSE,]$nzv)
length(nsv[nsv$percentUnique>2 & nsv$nzv==FALSE,]$nzv)
length(nsv[nsv$percentUnique>2 & nsv$nzv==TRUE,]$nzv)
M<-abs(cor(train_data2[,-118]))
diag(M)<-0
which(M>0.8,arr.ind=T)
length(which(M>0.8,arr.ind=T))
length(which(M>0.9,arr.ind=T))
length(which(M>0.85,arr.ind=T))
length(which(M>0.84,arr.ind=T))
which(M>0.85,arr.ind=T)
names(train_data2[,-drop_col])
names(train_data2[,-c(drop_col)])
drop_col
names(train_data2[,!(drop_col)])
names(train_data2[,!which(names(train_data2) %in% drop_col)])
names(train_data2[,!(names(train_data2) %in% drop_col)])
row.names(which(M>0.85,arr.ind=T))
row.names(which(M>0.70,arr.ind=T))
row.names(which(M>0.75,arr.ind=T))
!((row.names(which(M>0.75,arr.ind=T))) %in% (names(train_data2[,!(names(train_data2) %in% drop_col)])))
((row.names(which(M>0.75,arr.ind=T))) %in% (names(train_data2[,!(names(train_data2) %in% drop_col)])))
train_data3<-train_data2[,which(names(train_data2) %in% drop_col)]
test_data3<-test_data2[,which(names(test_data2) %in% drop_col)]
train_data3<-train_data2[,-which(names(train_data2) %in% drop_col)]
test_data3<-test_data2[,-which(names(test_data2) %in% drop_col)]
nsv2<-nearZeroVar(train_data3,saveMetrics=TRUE)
nsv2
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
library(caret)
modFit <- train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=testing)
rm(training)
rm(testing)
rm(iris)
rm(inTrain)
rm(modFit)
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
install.packages("ElemStatLearn", lib="C:/Program Files/R/R-3.1.2/library")
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA,nrow=10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
dim(ozone)[1]
dim(ozone)
ss <- sample(1:dim(ozone)[1],replace=T)
?sample
data.frame(ozone=1:155)
ll[1,]
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
ll <- matrix(NA,nrow=10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
lines(1:155,ll[1,],col="grey",lwd=2)
summary(ozone)
predictors = data.frame(ozone=ozone$ozone)
temperature = ozone$temperature
treebag <- bag(predictors, temperature, B = 10,
bagControl = bagControl(fit = ctreeBag$fit,
predict = ctreeBag$pred,
aggregate = ctreeBag$aggregate))
plot(ozone$ozone,temperature,col='lightgrey',pch=19)
points(ozone$ozone,predict(treebag$fits[[1]]$fit,predictors),pch=19,col="red")
points(ozone$ozone,predict(treebag,predictors),pch=19,col="blue")
ctreeBag$fit
rm(ll)
rm(ozone)
rm(ozone0)
rm(predictors)
rm(GCtorture)
rm(loess0)
rm(ss)
rm(temperature)
rm(treebag)
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
?train
?prox
getTree(modFit$finalModel,k=2)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=8,shape=4,data=irisP)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=8,shape=6,data=irisP)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
irisP
pred <- predict(modFit,testing); testing$predRight <- pred==testing$Species
table(pred,testing$Species)
qplot(Petal.Width,Petal.Length,colour=predRight,data=testing,main="newdata Predictions")
rm(inTrain)
rm(c(iris,irisP))
rm(c("iris","irisP"))
rm(iris,irisP)
rm(testing,training,modFit,p,pred,)
library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage <- subset(Wage,select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
rm(Wage,inTrain,testing,training)
train_data2_TEST<-subset(train_data1,.row.names(nsv[nsv$nzv==TRUE,]))
train_data2_TEST<-subset(train_data1,row.names(nsv[nsv$nzv==TRUE,]))
train_data2_TEST<-subset(train_data1,-row.names(nsv[nsv$nzv==TRUE,]))
row.names(nsv[nsv$nzv==TRUE,])
train_data2_TEST<-subset(train_data1,-as.list(row.names(nsv[nsv$nzv==TRUE,]))
)
train_data2<-train_data1[,-row.names(nsv[nsv$nzv==TRUE,])]
library(AppliedPredictiveModelind)
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
install.packages("pgmm", lib="C:/Program Files/R/R-3.1.2/library")
library(pgmm)
library(rpart)
data(segmentationOriginal)
> data(segmentationOriginal)
data(segmentationOriginal)
View(segmentationOriginal)
seg<-segmentationOriginal
View(seg)
View(seg)
training<-seg[Case=="Train",]
training<-seg[seg$Case=="Train",]
testing<-seg[seg$Case=="Test",]
modFit<-train(Class~.,method="rpart",data=training)
set.seed(125)
modFit<-train(Class~.,method="rpart",data=training)
print(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
plot(cartModel$finalModel, uniform=T)
plot(modFit$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
text(modFit$finalModel, cex=0.8)
library(pgmm)
data(olive)
olive = olive[,-1]
modFit<-train(Area~.,method="rpart",data=olive)
modFit<-train(Area~.,method="rpart2",data=olive)
predict(modFit,newdata=newdata = as.data.frame(t(colMeans(olive))))
predict(modFit,newdata = as.data.frame(t(colMeans(olive))))
View(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
modFit<-train(chd~.,method="glm",family="binomial",data=trainSA)
modFit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
modFit<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,data=trainSA,method="glm",family="binomial")
trainSA$chd<-as.factor(trainSA$chd)
modFit<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,data=trainSA,method="glm",family="binomial")
testSA$chd<-as.factor(testSA$chd)
set.seed(13234)
modFit<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((predict(modFit,newdata=testSA) > 0.5)*1) != testSA$chd)/length(test$chd)}
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
m<-missClass(testSA$chd,predict(modFit,newdata=testSA))
train_m<-missClass(trainSA$chd,predict(modFit,newdata=trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
train<-vowel.train
test<-vowel.train
View(train)
train$y<-as.factor(train$y)
test$y<-as.factor(test$y)
set.seed(33833)
modFit<-train(y~.,data=train,method="rf")
?varlmp
library(caret)
?varImp
modFit<-train(y~.,data=train,method="rf",importance=FALSE)
varImp(moddFit)
varImp(modFit)
?trainControl
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
View(train_data)
library(AppliedPredictiveModeling); library(caret); library(rattle); library(randomForest)
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
test_data<-read.csv("pml-testing.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
train_data1<-train_data[,8:length(train_data)]
test_data1<-test_data[,8:length(test_data)]
nsv<-nearZeroVar(train_data1,saveMetrics=TRUE)
nsv
summary(train_data1$avg_yaw_forearm)
str(train_data1$avg_yaw_forearm)
str(train_data1$var_yaw_forearm)
summary(train_data1$var_yaw_forearm)
train_data2<-train_data1[,-which(names(train_data1) %in% row.names(nsv[nsv$nzv==TRUE,]))]
test_data2<-test_data1[,-which(names(test_data1) %in% row.names(nsv[nsv$nzv==TRUE,]))]
dim(train_data2)
M<-abs(cor[train_data2[,-118]])
M<-abs(cor(train_data2[,-118]))
diag(M)<-0
which(M>0.8,arr.ind=T)
names(which(M>0.8,arr.ind=T))
row.names(which(M>0.8,arr.ind=T))
row.names(which(M>0.7,arr.ind=T))
unique(row.names(which(M>0.7,arr.ind=T)))
unique(row.names(which(M>0.6,arr.ind=T)))
unique(row.names(which(M>0.5,arr.ind=T)))
unique(row.names(which(M>0.4,arr.ind=T)))
unique(row.names(which(M>0.3,arr.ind=T)))
unique(row.names(which(M>0.2,arr.ind=T)))
unique(row.names(which(M>0.1,arr.ind=T)))
unique(row.names(which(M>0.1,arr.ind=T)))
unique(row.names(which(M>0.05,arr.ind=T)))
unique(row.names(which(M>0.01,arr.ind=T)))
M<-abs(cor(train_data2[,-118])); diag(M)<-0
useful_var<-unique(row.names(which(M>0.1,arr.ind=T)))
t<-subset(train_data2,usefuk_var)
t<-subset(train_data2,useful_var)
?subset
vars<-names(train_data2) %in% useful_var
useful_var<-c(useful_var,"Classe")
> vars<-names(train_data2) %in% useful_var
vars<-names(train_data2) %in% useful_var
train_data3<-[vars,]
train_data3<-[vars]
train_data3<-train_data2[vars]
names(train_data2)
useful_var<-c(useful_var,"classe")
vars<-names(train_data2) %in% useful_var
train_data3<-train_data2[vars,]
train_data3<-train_data2[vars]
test_data3<-test_data2[vars]
dim(train_data3);dim(test_data3)
all.unique(colnames(train_data3),colnames(test_data3))
all.equal(colnames(train_data3),colnames(test_data3))
names(train_data3)
names(test_data3)
all.equal(names(train_data3),names(test_data3))
set.seed(110567)
inTrain<-createDataPartition(y=train_data3$classe,p=0.70,list=FALSE)
training<-train_data3[inTrain,]
testing<-train_data3[inTrain,]
modFit<-train(classe~.,data=training,preProcess=c("center","scale"),trControl=trainControl(method="cv",number=4,allowParallel=TRUE),method="rf")
pred<-predict(modFit,newdata=testing)
confusionMatrix(pred,testing$classe)
modFit$finalModel
modFit
print(predict(modFit,neewdata=test_data3))
print(predict(modFit,newdata=test_data3))
install.packages("doParallel")
install.packages("doParallel")
saveRDS(modFit,"first_forest_model.Rds")
names(test_data3)
names(test_data3)
names(test_data2)
