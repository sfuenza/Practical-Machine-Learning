library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(trainSA)
modFit<-train(chd~.,method="glm",family="binomial",data=trainSA)
modFit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
modFit<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,data=trainSA,method="glm",family="binomial")
trainSA$chd<-as.factor(trainSA$chd)
modFit<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,data=trainSA,method="glm",family="binomial")
testSA$chd<-as.factor(testSA$chd)
set.seed(13234)
modFit<-train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((predict(modFit,newdata=testSA) > 0.5)*1) != testSA$chd)/length(test$chd)}
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
m<-missClass(testSA$chd,predict(modFit,newdata=testSA))
train_m<-missClass(trainSA$chd,predict(modFit,newdata=trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
train<-vowel.train
test<-vowel.train
View(train)
train$y<-as.factor(train$y)
test$y<-as.factor(test$y)
set.seed(33833)
modFit<-train(y~.,data=train,method="rf")
?varlmp
library(caret)
?varImp
modFit<-train(y~.,data=train,method="rf",importance=FALSE)
varImp(moddFit)
varImp(modFit)
?trainControl
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
View(train_data)
library(AppliedPredictiveModeling); library(caret); library(rattle); library(randomForest)
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
test_data<-read.csv("pml-testing.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
train_data1<-train_data[,8:length(train_data)]
test_data1<-test_data[,8:length(test_data)]
nsv<-nearZeroVar(train_data1,saveMetrics=TRUE)
nsv
summary(train_data1$avg_yaw_forearm)
str(train_data1$avg_yaw_forearm)
str(train_data1$var_yaw_forearm)
summary(train_data1$var_yaw_forearm)
train_data2<-train_data1[,-which(names(train_data1) %in% row.names(nsv[nsv$nzv==TRUE,]))]
test_data2<-test_data1[,-which(names(test_data1) %in% row.names(nsv[nsv$nzv==TRUE,]))]
dim(train_data2)
M<-abs(cor[train_data2[,-118]])
M<-abs(cor(train_data2[,-118]))
diag(M)<-0
which(M>0.8,arr.ind=T)
names(which(M>0.8,arr.ind=T))
row.names(which(M>0.8,arr.ind=T))
row.names(which(M>0.7,arr.ind=T))
unique(row.names(which(M>0.7,arr.ind=T)))
unique(row.names(which(M>0.6,arr.ind=T)))
unique(row.names(which(M>0.5,arr.ind=T)))
unique(row.names(which(M>0.4,arr.ind=T)))
unique(row.names(which(M>0.3,arr.ind=T)))
unique(row.names(which(M>0.2,arr.ind=T)))
unique(row.names(which(M>0.1,arr.ind=T)))
unique(row.names(which(M>0.1,arr.ind=T)))
unique(row.names(which(M>0.05,arr.ind=T)))
unique(row.names(which(M>0.01,arr.ind=T)))
M<-abs(cor(train_data2[,-118])); diag(M)<-0
useful_var<-unique(row.names(which(M>0.1,arr.ind=T)))
t<-subset(train_data2,usefuk_var)
t<-subset(train_data2,useful_var)
?subset
vars<-names(train_data2) %in% useful_var
useful_var<-c(useful_var,"Classe")
> vars<-names(train_data2) %in% useful_var
vars<-names(train_data2) %in% useful_var
train_data3<-[vars,]
train_data3<-[vars]
train_data3<-train_data2[vars]
names(train_data2)
useful_var<-c(useful_var,"classe")
vars<-names(train_data2) %in% useful_var
train_data3<-train_data2[vars,]
train_data3<-train_data2[vars]
test_data3<-test_data2[vars]
dim(train_data3);dim(test_data3)
all.unique(colnames(train_data3),colnames(test_data3))
all.equal(colnames(train_data3),colnames(test_data3))
names(train_data3)
names(test_data3)
all.equal(names(train_data3),names(test_data3))
set.seed(110567)
inTrain<-createDataPartition(y=train_data3$classe,p=0.70,list=FALSE)
training<-train_data3[inTrain,]
testing<-train_data3[inTrain,]
modFit<-train(classe~.,data=training,preProcess=c("center","scale"),trControl=trainControl(method="cv",number=4,allowParallel=TRUE),method="rf")
pred<-predict(modFit,newdata=testing)
confusionMatrix(pred,testing$classe)
modFit$finalModel
modFit
print(predict(modFit,neewdata=test_data3))
print(predict(modFit,newdata=test_data3))
install.packages("doParallel")
install.packages("doParallel")
saveRDS(modFit,"first_forest_model.Rds")
names(test_data3)
names(test_data3)
names(test_data2)
###Load Data
First we need to read the files (included in the repo). After an analysis of the data, to avoid problems with missing data I decided to consider as NA's: ["NA", "#DIV/0!", ""], considering them as moments when the user didn't do anything or problems with the devices gathering the data.
library(AppliedPredictiveModeling); library(caret); library(rattle); library(randomForest); library(doParallel); library(rpart); library(rpart.plot); library(e1071)
registerDoParallel(cores=2)
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
test_data<-read.csv("pml-testing.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
#First 7 columns aren't useful for the model (name, time, window, etc...)
train_data1<-train_data[,8:length(train_data)]
test_data1<-test_data[,8:length(test_data)]
#NearZeroVar gives us a first approach of columns that we don't need
nsv<-nearZeroVar(train_data1,saveMetrics=TRUE)
#We exclude the columns that NZV is TRUE (almost all of them are 0 or NA)
train_data2<-train_data1[,-which(names(train_data1) %in% row.names(nsv[nsv$nzv==TRUE,]))]
test_data2<-test_data1[,-which(names(test_data1) %in% row.names(nsv[nsv$nzv==TRUE,]))]
dim(train_data2)
M<-abs(cor(train_data2[,-118])); diag(M)<-0
useful_var<-unique(row.names(which(M>0.1,arr.ind=T)))
useful_var<-c(useful_var,"classe")
#Now we subset the train and test data using this columns
vars<-names(train_data2) %in% useful_var
train_data3<-train_data2[vars]
test_data3<-test_data2[vars]
#Just to be sure we check if both data sets have the same columns
all.equal(names(train_data3),names(test_data3))
set.seed(110567)
inTrain<-createDataPartition(y=train_data3$classe,p=0.70,list=FALSE)
training<-train_data3[inTrain,]
testing<-train_data3[-inTrain,]
modFit<- readRDS("first_forest_model.Rds")
pred<-predict(modFit,newdata=testing)
confusionMatrix(pred,testing$classe)
modFit$finalModel
print(predict(modFit,newdata=test_data3))
plot(modFit$finalModel,log="y",main="Model error by each Classe")
legend("top", colnames((modFit$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
test_data<-read.csv("pml-testing.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
train_data<-train_data[,8:length(train_data)]
test_data<-test_data[,8:length(test_data)]
#NearZeroVar gives us a first approach of columns that we don't need
nsv<-nearZeroVar(train_data1,saveMetrics=TRUE)
#We exclude the columns that NZV is TRUE (almost all of them are 0 or NA)
train_data<-train_data[,-which(names(train_data) %in% row.names(nsv[nsv$nzv==TRUE,]))]
test_data<-test_data[,-which(names(test_data) %in% row.names(nsv[nsv$nzv==TRUE,]))]
dim(train_data)
train_data<-train_data[,8:length(train_data)]
test_data<-test_data[,8:length(test_data)]
#NearZeroVar gives us a first approach of columns that we don't need
nsv<-nearZeroVar(train_data,saveMetrics=TRUE)
#We exclude the columns that NZV is TRUE (almost all of them are 0 or NA)
train_data<-train_data[,-which(names(train_data) %in% row.names(nsv[nsv$nzv==TRUE,]))]
test_data<-test_data[,-which(names(test_data) %in% row.names(nsv[nsv$nzv==TRUE,]))]
dim(train_data)
M<-abs(cor(train_data[,-118])); diag(M)<-0
useful_var<-unique(row.names(which(M>0.1,arr.ind=T)))
useful_var<-c(useful_var,"classe")
#Now we subset the train and test data using this columns
vars<-names(train_data) %in% useful_var
train_data<-train_data[vars]
test_data<-test_data[vars]
#Just to be sure we check if both data sets have the same columns
all.equal(names(train_data),names(test_data))
M<-abs(cor(train_data[,-112])); diag(M)<-0
useful_var<-unique(row.names(which(M>0.1,arr.ind=T)))
useful_var<-c(useful_var,"classe")
#Now we subset the train and test data using this columns
vars<-names(train_data) %in% useful_var
train_data<-train_data[vars]
test_data<-test_data[vars]
#Just to be sure we check if both data sets have the same columns
all.equal(names(train_data),names(test_data))
train_data<-read.csv("pml-training.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
test_data<-read.csv("pml-testing.csv",header=TRUE,na.strings=c("NA","#DIV/0!",""))
train_data<-train_data[,8:length(train_data)]
test_data<-test_data[,8:length(test_data)]
nsv<-nearZeroVar(train_data,saveMetrics=TRUE)
train_data<-train_data[,-which(names(train_data) %in% row.names(nsv[nsv$nzv==TRUE,]))]
test_data<-test_data[,-which(names(test_data) %in% row.names(nsv[nsv$nzv==TRUE,]))]
dim(train_data)
M<-abs(cor(train_data[,-112])); diag(M)<-0
M<-abs(cor(train_data[,-118])); diag(M)<-0
useful_var<-unique(row.names(which(M>0.1,arr.ind=T)))
useful_var<-c(useful_var,"classe")
vars<-names(train_data) %in% useful_var
train_data<-train_data[vars]
test_data<-test_data[vars]
all.equal(names(train_data),names(test_data))
set.seed(110567)
set.seed(110567)
inTrain<-createDataPartition(y=train_data$classe,p=0.70,list=FALSE)
training<-train_data[inTrain,]
testing<-train_data[-inTrain,]
modFit_tree <- train(classe ~ .,  preProcess=c("center", "scale"), trControl=trainControl(method = "cv", number = 4), data = training, method="rpart")
print(modFit_tree, digits=3)
predic_tree<-predict(modFit_tree,newdata=testing)
confusionMatrix(predic_tree,testing$classe)
set.seed(110567)
modFit_Fo_cv<-train(classe ~ ., method="rf", trControl=trainControl(method = "cv", number = 4), data=training)
prin(modFit_Fo_cv)
print(modFit_Fo_cv)
predic_Fo_cv<-predict(modFit_Fo_cv,newdata=testing)
confusionMatrix(predic_Fo_cv,testing$classe)
modFit_Fo_pp<-train(classe ~ ., method="rf", preProcess=c("center", "scale"), data=training)
print(modFit_Fo_pp)
predic_Fo_pp<-predict(modFit_Fo_pp,newdata=testing)
confusionMatrix(predic_Fo_pp,testing$classe)
install.packages("ROCR")
library(ROCR)
perf_tree <- performance(predic_tree, measure = "tpr", x.measure = "fpr")
perf_tree <- performance(predic_tree)
perf_tree <- performance(predic_tree, measure = "tpr")
?performance
pred_tree<-prediction(predic_tree,testing$classe)
?prediction
predic_tree
summary(predic_tree)
str(predic_tree)
pred_tree<-prediction(predic_tree,testing$classe)
modFit_tree
pred_tree<-prediction(modFit_tree,testing$classe)
?ROC.curve
conf_tree<-confusionMatrix(predic_Fo_pp,testing$classe)
plot(conf_tree)
print(conf_tree)
plot(as.data.frame(conf_tree))
ggplot(conf_tree)
print(conf_tree)
print(conf_tree,printStats = TRUE)
print(conf_tree,printStats = FALSE)
confusionImage(conf_tree)
install.packages("mlearning")
library(mlearning)
confusionImage(conf_tree)
plot(conf_tree)
trellis.par.set(caretTheme())
plot(conf_tree)
plot(prdeic_tree)
plot(predic_tree)
plot(predic_tree,metric="Kappa")
ggplot(predic_tree)
ggplot(modFit_tree)
plot(modFit_tree)
plot(modFit_tree$finalModel)
resamps<-resamples(list(TREE=modFit_tree,FO_CV=modFit_Fo_cv,FO_PP=modFit_Fo_pp))
resamps<-resamples(list(FO_CV=modFit_Fo_cv,FO_PP=modFit_Fo_pp))
bwplot(modFit_tree)
bwplot(modFit_tree$finalModel)
bwplot(modFit_Fo_cv$finalModel)
xyplot(modFit_Fo_cv)
fancyRpartPlot(modFit_tree)
fancyRpartPlot(modFit_tree$finalModel)
saveRDS(modFit_tree,"modFit_tree.RDS")
saveRDS(modFit_Fo_cv,"modFit_Fo_cv.RDS")
saveRDS(modFit_Fo_pp,"modFit_Fo_pp.RDS")
fancyRpartPlot(modFit_tree$finalModel)
fancyRpartPlot(modFit_tree$finalModel)
plot(modFit_tree$finalModel,log="y",main="Model error by each Classe")
legend("top", colnames((modFit_tree$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_tree$finalModel,log="y",main="Model error by each Classe")
plot(modFit_Fo_cv$finalModel,log="y",main="Model error by each Classe")
plot(modFit_Fo_pp$finalModel,log="y",main="Model error by each Classe")
modFit_Fo_cvpp<-readRDS("modFit_Fo_cvpp.Rds")
modFit_Fo_cvpp<-readRDS("modFit_Fo_cvpp.RDS")
modFit_Fo_cvpp<-readRDS("modFit_Fo_cvpp.RDS")
predic_Fo_cvpp<-predict(modFit_Fo_cvpp,newdata=testing)
confusionMatrix(predic_Fo_cvpp,testing$classe)
par(mfrow=c(2,2))
plot(modFit_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_cv$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_pp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_cvpp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
#legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
#legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
#legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:4,cex=0.2,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
#legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:4,cex=0.4,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
#legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:4,cex=0.5,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
#legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.8,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:4,cex=0.5,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.5,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:3,cex=0.45,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),cex=0.45,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),cex=0.45)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),cex=0.45,fill=1:2)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),cex=0.45,fill=1:5)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:5)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:5)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),cex=0.45,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:5,cex=0.45,fill=1:4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:4,cex=0.45,fill=1:4)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("top", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("top", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("top", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6,text.width = 4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6,text.width = 10)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="Random Forest with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6,pt.cex = 1)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.8,fill=1:6,pt.cex = 1)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6,pt.cex = 2)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6,pt.cex = 4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6,pch=4)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6,pch=10)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.6,fill=1:6,pt.cex=1)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.6,fill=1:6)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.45,fill=1:6)
par(mfrow=c(2,2))
plot(modFit_Fo_cv$finalModel,log="y",main="Random Forest with Cross Validation")
legend("topright", colnames((modFit_Fo_cv$finalModel)$err.rate),col=1:6,cex=0.6,fill=1:6)
plot(modFit_Fo_pp$finalModel,log="y",main="Random Forest with PreProcession")
legend("topright", colnames((modFit_Fo_pp$finalModel)$err.rate),col=1:6,cex=0.6,fill=1:6)
plot(modFit_Fo_cvpp$finalModel,log="y",main="RF with Cross Validation and PreProcessing")
legend("topright", colnames((modFit_Fo_cvpp$finalModel)$err.rate),col=1:6,cex=0.6,fill=1:6)
set.seed(110567)
modFit_Fo_cvpp<-train(classe~.,data=training,preProcess=c("center","scale"),trControl=trainControl(method="cv",number=4,allowParallel=TRUE),method="rf")
pred_test<-predict(modFit_Fo_cvpp,newdata=test_data)
pred_test
answers = rep("A", 20)
pred_test[1]
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(pred_test)
pred_test2<-predict(modFit_Fo_cv,newdata=test_data)
saveRDS(modFit_Fo_cvpp,"modFit_Fo_cvpp.RDS")
predic_Fo_pp<-predict(modFit_Fo_pp,newdata=testing)
confusionMatrix(predic_Fo_pp,testing$classe)
predic_Fo_cvpp<-predict(modFit_Fo_cvpp,newdata=testing)
confusionMatrix(predic_Fo_cvpp,testing$classe)
pred_test
pred_test2
pred_test3<-predict(modFit_Fo_pp,newdata=test_data)
pred_test3
